# Ollama Crew Configuration
#OLLAMA_HOST="http://localhost:11434"
#OLLAMA_MODEL="gemma-3:4b"

# Gemini Configuration
# MODEL="gemini/gemini-2.0-flash"
#GEMINI_API_KEY="<API_KEY>"
#LANGTRACE_API_KEY="<API_KEY>"

# LM Studio Configuration
#LMSTUDIO_API_URL="http://10.26.112.79:1234"
#LMSTUDIO_API_VERSION="v1"
#LMSTUDIO_CHAT_API_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/chat/completions"
#LMSTUDIO_MODEL_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/models/${LMSTUDIO_MODEL}"
#LMSTUDIO_COMPLETIONS_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/completions"
#LMSTUDIO_EMBEDDINGS_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/embeddings"
#LMSTUDIO_MODEL_EMB="text-embedding-nomic-embed-text-v1.5"
#LMSTUDIO_MODEL="gemma-3-4b-it"

# Langchain Configuration
#LANGCHAIN_API_KEY="API_KEY"

# MLflow Configuration
#MLFLOW_TRACKING_URI=postgresql://postgres:password@localhost:5432/mlflow_tracking
#MLFLOW_EXPERIMENT_NAME=ollama_crew_monitoring
#MLFLOW_ARTIFACTS_PATH=./mlflow-artifacts

# Performance Monitoring
MONITOR_LOG_LEVEL=INFO
PERFORMANCE_THRESHOLD_CPU=80
PERFORMANCE_THRESHOLD_MEMORY=1000
EXECUTION_TIMEOUT=300

# API Keys and External Services
SERPER_API_KEY=your_serper_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # Optional: for comparison testing

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=ollama.log
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# System Configuration
MAX_PARALLEL_TASKS=3
DEFAULT_ANALYSIS_DEPTH=detailed
DEFAULT_BRANCH_DEPTH=3
VALIDATION_LEVEL=normal

# Output Configuration
OUTPUT_DIR=./outputs
TEMPLATE_DIR=./templates
CONFIG_DIR=./config

# Alert Configuration
ALERT_EMAIL=admin@example.com
ALERT_THRESHOLD_CRITICAL=5
ALERT_THRESHOLD_WARNING=3

# Cache Configuration
CACHE_ENABLED=true
CACHE_DIR=./cache
CACHE_RETENTION_DAYS=7

# Development Settings
DEBUG=false
DEVELOPMENT_MODE=false
PROFILE_CODE=false

# Security Settings
ENABLE_SSL=false
SSL_CERT_PATH=
SSL_KEY_PATH=

# Documentation
DOCS_AUTO_GENERATE=true
DOCS_OUTPUT_DIR=./docs
