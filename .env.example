# Ollama Crew Configuration
#OLLAMA_HOST="http://localhost:11434"
#OLLAMA_MODEL="gemma-3:4b"

# Gemini Configuration
# MODEL="gemini/gemini-2.0-flash"
#GEMINI_API_KEY="<API_KEY>"
#LANGTRACE_API_KEY="<API_KEY>"

# Gemini Configuration
GEMINI_MODEL="models/gemini-2.0-flash"
GEMINI_API_KEY=""
GEMINI_MAX_TOKENS=8192
GEMINI_INPUT_TOKENS=1048576
GEMINI_CONTEXT_SIZE=1048576
GEMINI_MODEL_URL="https://api.gemini.com/v1/models/${GEMINI_MODEL}"
GEMINI_CHAT_API_URL="https://api.gemini.com/v1/chat/completions"
GEMINI_COMPLETIONS_URL="https://api.gemini.com/v1/completions"
GEMINI_EMBEDDINGS_URL="https://api.gemini.com/v1/embeddings"
GEMINI_TEMPERATURE=0.7
GEMINI_TOP_P=0.95
GEMINI_STRUCTURED_MODE=true
GEMINI_THINKING_MODE=experimental
GEMINI_FEATURES="structured_output,function_calling,code_execution,search,tool_use,thinking"
GEMINI_EXPERIMENTAL="image_generation,live_api,thinking"
GEMINI_COMING_SOON="audio_generation,caching"

# Serper Configuration
SERPER_API_KEY="your_serper_api_key_here"
# LM Studio Configuration
#LMSTUDIO_API_URL="http://10.26.112.79:1234"
#LMSTUDIO_API_VERSION="v1"
#LMSTUDIO_CHAT_API_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/chat/completions"
#LMSTUDIO_MODEL_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/models/${LMSTUDIO_MODEL}"
#LMSTUDIO_COMPLETIONS_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/completions"
#LMSTUDIO_EMBEDDINGS_URL="${LMSTUDIO_API_URL}/${LMSTUDIO_API_VERSION}/embeddings"
#LMSTUDIO_MODEL_EMB="text-embedding-nomic-embed-text-v1.5"
#LMSTUDIO_MODEL="gemma-3-4b-it"

# LM Studio Configuration
LMSTUDIO_API_URL="http://localhost:1234"
LMSTUDIO_MODEL="gemma-3-4b-it"
LMSTUDIO_CONTEXT_SIZE=4096
LMSTUDIO_MAX_TOKENS=2048
LMSTUDIO_TEMPERATURE=0.7
LMSTUDIO_TOP_P=0.95
LMSTUDIO_RESPONSE_FORMAT="json"

# Langchain Configuration
#LANGCHAIN_API_KEY="API_KEY"

# MLflow Configuration
MLFLOW_TRACKING_URI=postgresql://postgres:password@localhost:5432/mlflow_tracking

# Performance Monitoring
MONITOR_LOG_LEVEL=INFO
PERFORMANCE_THRESHOLD_CPU=80
PERFORMANCE_THRESHOLD_MEMORY=1000
EXECUTION_TIMEOUT=300

# API Keys and External Services
SERPER_API_KEY=your_serper_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # Optional: for comparison testing

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=ollama.log
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# System Configuration
MAX_PARALLEL_TASKS=3
DEFAULT_ANALYSIS_DEPTH=detailed
DEFAULT_BRANCH_DEPTH=3
VALIDATION_LEVEL=normal

# Model Selection and Coordination
MODEL_PRIORITY=["gemini", "lmstudio", "ollama"]
ENABLE_MODEL_FALLBACK=true
PARALLEL_MODEL_EXECUTION=false

# Output Configuration
OUTPUT_DIR=./outputs
TEMPLATE_DIR=./templates
CONFIG_DIR=./config

# Alert Configuration
ALERT_EMAIL=admin@example.com
ALERT_THRESHOLD_CRITICAL=5
ALERT_THRESHOLD_WARNING=3

# Cache Configuration
CACHE_ENABLED=true
CACHE_DIR=./cache
CACHE_RETENTION_DAYS=7

# Development Settings
DEBUG=false
DEVELOPMENT_MODE=false
PROFILE_CODE=false

# Security Settings
ENABLE_SSL=false
SSL_CERT_PATH=
SSL_KEY_PATH=

# Documentation
DOCS_AUTO_GENERATE=true
DOCS_OUTPUT_DIR=./docs
